
<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
import asyncio
from datetime import datetime, timedelta
from unittest.mock import AsyncMock, MagicMock, Mock, call, patch

from pydantic import Field, HttpUrl, NonNegativeInt
from tqdm.notebook import tqdm

from fastkafka._components.helpers import true_after
from fastkafka._components.logger import supress_timestamps
from fastkafka._helpers import produce_messages
from fastkafka.encoder import avro_decoder, avro_encoder, json_decoder
from fastkafka.testing import ApacheKafkaBroker
```

``` python
# allows async calls in notebooks

import nest_asyncio
```

``` python
nest_asyncio.apply()
```

``` python
supress_timestamps()
logger = get_logger(__name__, level=20)
logger.info("ok")
```

    [INFO] __main__: ok

``` python
class MyMessage(BaseModel):
    url: HttpUrl = Field(..., example="http://www.acme.com", description="Url example")
    port: NonNegativeInt = Field(1000)
```

``` python
def create_consumer_record(topic: str, partition: int, msg: BaseModel):
    record = ConsumerRecord(
        topic=topic,
        partition=partition,
        offset=0,
        timestamp=0,
        timestamp_type=0,
        key=None,
        value=msg.json().encode("utf-8")
        if hasattr(msg, "json")
        else msg.encode("utf-8"),
        checksum=0,
        serialized_key_size=0,
        serialized_value_size=0,
        headers=[],
    )
    return record
```

``` python
# Check if callback is called when wrapped

example_msg = "Example msg"
callback = AsyncMock()
safe_callback = _create_safe_callback(callback)

await safe_callback(f"{example_msg}")

callback.assert_awaited_once_with(f"{example_msg}")
```

``` python
# Check if exception is caught and logged when callback is called and throws an exception

with patch.object(logger, "warning") as mock:
    example_msg = "Example msg"
    exception = Exception("")

    callback = AsyncMock()
    callback.side_effect = exception
    safe_callback = _create_safe_callback(callback)

    await safe_callback(f"{example_msg}")

    callback.assert_awaited_once_with(f"{example_msg}")
    mock.assert_called_once_with(
        f"_safe_callback(): exception caugth {exception.__repr__()} while awaiting '{callback}({example_msg})'"
    )
```

``` python
# Check if callback is called when wrapped

for is_async in [False, True]:
    example_msg = "Example msg"
    callback = AsyncMock() if is_async else Mock()
    prepared_callback = _prepare_callback(callback)

    await prepared_callback(f"{example_msg}")

    callback.assert_called_once_with(f"{example_msg}")
```

``` python
# Sanity check: one msg, one topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic = "topic_0"
    partition = 0
    topic_part_0_0 = TopicPartition(topic, partition)
    msg = MyMessage(url="http://www.acme.com", port=22)
    record = create_consumer_record(topic=topic, partition=partition, msg=msg)

    await _stream_msgs(
        msgs={topic_part_0_0: [record]},
        send_stream=send_stream,
    )

    mock.assert_called_once()
    mock.assert_has_calls([call([record])])
```

``` python
# Check different topics

# Two msg, two topics, send called twice with each topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic_partitions = [("topic_0", 0), ("topic_1", 0)]

    msg = MyMessage(url="http://www.acme.com", port=22)
    msgs = {
        TopicPartition(topic, partition): [
            create_consumer_record(topic=topic, partition=partition, msg=msg)
        ]
        for topic, partition in topic_partitions
    }

    await _stream_msgs(
        msgs=msgs,
        send_stream=send_stream,
    )

    assert mock.call_count == 2

    mock.assert_has_calls([call(msg) for msg in msgs.values()])
```

``` python
# Check multiple msgs in same topic

# Two msg, one topic, send called twice for same topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic_partitions = [("topic_0", 0)]

    msg = MyMessage(url="http://www.acme.com", port=22)
    record = create_consumer_record(topic=topic, partition=partition, msg=msg)

    msgs = {
        TopicPartition(topic, partition): [
            create_consumer_record(topic=topic, partition=partition, msg=msg),
            create_consumer_record(topic=topic, partition=partition, msg=msg),
        ]
        for topic, partition in topic_partitions
    }

    await _stream_msgs(
        msgs=msgs,
        send_stream=send_stream,
    )

    mock.assert_has_calls([call(msg) for msg in msgs.values()])
```

``` python
# Check multiple partitions

# Two msg, one topic, differenct partitions, send called twice for same topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic_partitions = [("topic_0", 0), ("topic_0", 1)]

    msg = MyMessage(url="http://www.acme.com", port=22)
    msgs = {
        TopicPartition(topic, partition): [
            create_consumer_record(topic=topic, partition=partition, msg=msg)
        ]
        for topic, partition in topic_partitions
    }
    record = create_consumer_record(topic=topic, partition=partition, msg=msg)

    await _stream_msgs(
        msgs=msgs,
        send_stream=send_stream,
    )

    mock.assert_has_calls([call(msg) for msg in msgs.values()])
```

``` python
def is_shutting_down_f(mock_func: Mock, num_calls: int = 1) -> Callable[[], bool]:
    def _is_shutting_down_f():
        return mock_func.call_count == num_calls

    return _is_shutting_down_f
```

``` python
topic = "topic_0"
partition = 0
msg = MyMessage(url="http://www.acme.com", port=22)
record = create_consumer_record(topic=topic, partition=partition, msg=msg)

mock_consumer = MagicMock()
msgs = {TopicPartition(topic, 0): [record]}

f = asyncio.Future()
f.set_result(msgs)
mock_consumer.configure_mock(**{"getmany.return_value": f})
mock_callback = Mock()


for is_async in [True, False]:
    await _aiokafka_consumer_loop(
        consumer=mock_consumer,
        topic=topic,
        decoder_fn=json_decoder,
        max_buffer_size=100,
        timeout_ms=10,
        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,
        msg_type=MyMessage,
        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),
    )

    assert mock_consumer.getmany.call_count == 1
    mock_callback.assert_called_once_with(msg)
```

``` python
# Sanity check: exception in callback recovery
# Two msg, one topic, process_f called twice even tough it throws

topic = "topic_0"
partition = 0
msg = MyMessage(url="http://www.acme.com", port=22)
record = create_consumer_record(topic=topic, partition=partition, msg=msg)

num_msgs = 2

mock_consumer = MagicMock()
msgs = {TopicPartition(topic, 0): [record, record]}

f = asyncio.Future()
f.set_result(msgs)

mock_consumer.configure_mock(**{"getmany.return_value": f})
mock_callback = Mock()

exception = Exception("")
mock_callback.side_effect = exception

for is_async in [True, False]:
    await _aiokafka_consumer_loop(
        consumer=mock_consumer,
        topic=topic,
        decoder_fn=json_decoder,
        max_buffer_size=100,
        timeout_ms=1,
        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,
        msg_type=MyMessage,
        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany, num_calls=1),
    )

    assert mock_callback.call_count == num_msgs, mock_callback.call_count
    mock_callback.assert_has_calls([call(msg), call(msg)])

print("ok")
```

    [WARNING] __main__: _safe_callback(): exception caugth Exception('') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'
    [WARNING] __main__: _safe_callback(): exception caugth Exception('') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'
    ok

``` python
# Sanity check: malformed msgs
# One msg of wrong type, two normal msg, one topic, process_f called twice

topic = "topic_0"
partition = 0
msg = MyMessage(url="http://www.acme.com", port=22)
correct_record = create_consumer_record(topic=topic, partition=partition, msg=msg)
faulty_record = create_consumer_record(topic=topic, partition=partition, msg="Wrong!")

mock_consumer = MagicMock()
msgs = {TopicPartition(topic, 0): [faulty_record, correct_record, correct_record]}

mock_consumer.configure_mock(**{"getmany.return_value": f})
mock_callback = Mock()

exception = Exception("")
callback.side_effect = exception

for is_async in [True, False]:
    await _aiokafka_consumer_loop(
        consumer=mock_consumer,
        topic=topic,
        decoder_fn=json_decoder,
        max_buffer_size=100,
        timeout_ms=10,
        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,
        msg_type=MyMessage,
        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),
    )

    assert mock_consumer.getmany.call_count == 1
    mock_callback.assert_has_calls([call(msg), call(msg)])

print("ok")
```

    ok

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/aiokafka_consumer_loop.py#L180"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### sanitize_kafka_config

>      sanitize_kafka_config (**kwargs:Any)

Sanitize Kafka config

``` python
kwargs = {
    "bootstrap_servers": "whatever.cloud:9092",
    "auto_offset_reset": "earliest",
    "security_protocol": "SASL_SSL",
    "sasl_mechanism": "PLAIN",
    "sasl_plain_username": "username",
    "sasl_plain_password": "password",
    "ssl_context": "something",
}

assert sanitize_kafka_config(**kwargs)["sasl_plain_password"] == "********"
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/aiokafka_consumer_loop.py#L187"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### aiokafka_consumer_loop

>      aiokafka_consumer_loop (topic:str,
>                              decoder_fn:Callable[[bytes,pydantic.main.ModelMet
>                              aclass],Any], timeout_ms:int=100,
>                              max_buffer_size:int=100000, callback:Callable[[py
>                              dantic.main.BaseModel],Union[NoneType,Awaitable[N
>                              oneType]]],
>                              msg_type:Type[pydantic.main.BaseModel],
>                              is_shutting_down_f:Callable[[],bool],
>                              max_records=None, **kwargs:Any)

Consumer loop for infinite pooling of the AIOKafka consumer for new
messages. Creates and starts AIOKafkaConsumer and runs
\_aio_kafka_consumer loop fo infinite poling of the consumer for new
messages.

Args: topic: name of the topic to subscribe to decoder_fn: Function to
decode the messages consumed from the topic callback: callback function
to be called after decoding and parsing a consumed message timeout_ms:
Time to timeut the getmany request by the consumer max_buffer_size:
Maximum number of unconsumed messages in the callback buffer msg_type:
Type with `parse_json` method used for parsing a decoded message
is_shutting_down_f: Function for controlling the shutdown of consumer
loop callbacks: Dict of callbacks mapped to their respective topics
msg_types: Dict of message types mapped to their respective topics
partitions (list\[TopicPartition\]): The partitions that need fetching
message. If no one partition specified then all subscribed partitions
will be used

``` python
topic = "test_topic"
msgs_sent = 9178
msgs = [
    MyMessage(url="http://www.ai.com", port=port).json().encode("utf-8")
    for port in range(msgs_sent)
]
msgs_received = 0


async def count_msg(msg: MyMessage):
    global msgs_received
    msgs_received = msgs_received + 1
    if msgs_received % 1000 == 0:
        logger.info(f"{msgs_received=}")


async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
    await aiokafka_consumer_loop(
        topic=topic,
        decoder_fn=json_decoder,
        auto_offset_reset="earliest",
        callback=count_msg,
        msg_type=MyMessage,
        is_shutting_down_f=true_after(2),
        bootstrap_servers=bootstrap_server,
    )

    assert msgs_sent == msgs_received, f"{msgs_sent} != {msgs_received}"
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 606654...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 606654 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 606282...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 606282 terminated.

``` python
# Test with avro_decoder

topic = "test_topic"
msgs_sent = 9178
msgs = [
    avro_encoder(MyMessage(url="http://www.ai.com", port=port))
    for port in range(msgs_sent)
]
msgs_received = 0


async def count_msg(msg: MyMessage):
    global msgs_received
    msgs_received = msgs_received + 1
    if msgs_received % 1000 == 0:
        logger.info(f"{msgs_received=}")


async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
    await aiokafka_consumer_loop(
        topic=topic,
        decoder_fn=avro_decoder,
        auto_offset_reset="earliest",
        callback=count_msg,
        msg_type=MyMessage,
        is_shutting_down_f=true_after(2),
        bootstrap_servers=bootstrap_server,
    )

    assert msgs_sent == msgs_received, f"{msgs_sent} != {msgs_received}"
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 607858...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 607858 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 607486...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 607486 terminated.

``` python
topic = "test_topic"
msgs_sent = 500_00
msgs = [
    MyMessage(url="http://www.ai.com", port=port).json().encode("utf-8")
    for port in range(msgs_sent)
]


async def count_msg(msg: MyMessage):
    pbar.update(1)


def _is_shutting_down_f():
    return pbar.n >= pbar.total


async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
    with tqdm(total=msgs_sent, desc="consuming messages") as _pbar:
        global pbar
        pbar = _pbar

        start = datetime.now()
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=json_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=_is_shutting_down_f,
            bootstrap_servers=bootstrap_server,
        )
        t = (datetime.now() - start) / timedelta(seconds=1)
        thrp = pbar.n / t

        print(f"Messages processed: {pbar.n:,d}")
        print(f"Time              : {t:.2f} s")
        print(f"Throughput.       : {thrp:,.0f} msg/s")
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 50,000
    Time              : 0.72 s
    Throughput.       : 69,657 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 609063...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 609063 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 608691...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 608691 terminated.

``` python
# Test with avro_decoder

topic = "test_topic"
msgs_sent = 500_00
msgs = [
    avro_encoder(MyMessage(url="http://www.ai.com", port=port))
    for port in range(msgs_sent)
]


async def count_msg(msg: MyMessage):
    pbar.update(1)


def _is_shutting_down_f():
    return pbar.n >= pbar.total


async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
    with tqdm(total=msgs_sent, desc="consuming messages") as _pbar:
        global pbar
        pbar = _pbar

        start = datetime.now()
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=avro_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=_is_shutting_down_f,
            bootstrap_servers=bootstrap_server,
        )
        t = (datetime.now() - start) / timedelta(seconds=1)
        thrp = pbar.n / t

        print(f"Messages processed: {pbar.n:,d}")
        print(f"Time              : {t:.2f} s")
        print(f"Throughput.       : {thrp:,.0f} msg/s")
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 50,000
    Time              : 1.62 s
    Throughput.       : 30,849 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 610265...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 610265 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 609892...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 609892 terminated.
